{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKggMaPae6bJ"
   },
   "source": [
    "# CMT 309 Data Science Portfolio\n",
    "# Parts 1 and 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2054492"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Pe7XhS9wEVw"
   },
   "source": [
    "# Part 1 - Pre-processing and exploratory analysis\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Answer the questions by filling in the appropriate sections of this file. \n",
    "- Do not remove or rename section headings or any code that has been provided, unless instructed otherwise.\n",
    "- You can add as many additional cells with code as you like.\n",
    "\n",
    "Before submitting,\n",
    "\n",
    "- Ensure that the code is clean, readable, and well documented. \n",
    "- Restart the kernel (to wipe all variables) and then run the code from top to bottom to produce all intermediate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1300,
     "status": "ok",
     "timestamp": 1621352489302,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "acSREWbeG0mm"
   },
   "outputs": [],
   "source": [
    "import scipy, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# add more imports here if you like\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1621352489302,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "ycIjzElBzG2x"
   },
   "outputs": [],
   "source": [
    "# change this line your folder where the data is found\n",
    "basedir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwuEFzzUKzJW"
   },
   "source": [
    "In this part you will be working with the  `listings.csv` data. To help you wrap around your head we will first provide some information on the main columns in the data.\n",
    "\n",
    "***Dataframe columns description***:\n",
    "\n",
    "- `id` - unique ID identifying the listing\n",
    "\n",
    "- `name` - title of the listing\n",
    "\n",
    "- `host_id` - unique ID for a host\n",
    "\n",
    "- `host_name` - first name of the host\n",
    "\n",
    "- `host_since` - date that the host first joined Airbnb\n",
    "\n",
    "- `host_is_superhost` - whether or not the host is a superhost, which is a mark of quality for the top-rated and most experienced hosts, and can increase your search ranking on Airbnb\n",
    "\n",
    "- `host_listings_count` - how many listings the host has in total\n",
    "\n",
    "- `host_has_profile_pic` - whether or not the host has a profile picture\n",
    "\n",
    "- `host_identity_verified` - whether or not the host has been verified with his passport\n",
    "\n",
    "- `neighbourhood_cleansed` - the borough the property is in\n",
    "\n",
    "- `latitude` and `longitude` - geolocation coordinates of the property\n",
    "\n",
    "- `property_type` - type of property, e.g. house or flat\n",
    "\n",
    "- `room_type` - type of listing, e.g. entire home, private room or shared room\n",
    "\n",
    "- `accommodates` - how many people the property accommodates\n",
    "\n",
    "- `bedrooms` - number of bedrooms\n",
    "\n",
    "- `beds` - number of beds\n",
    "\n",
    "- `price` - nightly advertised price (the target variable)\n",
    "\n",
    "- `minimum_nights` - the minimum length of stay\n",
    "\n",
    "- `maximum_nights` - the maximum length of stay\n",
    "\n",
    "- `availability_30` - how many nights are available to be booked in the next 30 days\n",
    "\n",
    "- `availability_60` - how many nights are available to be booked in the next 60 days\n",
    "\n",
    "- `availability_90` - how many nights are available to be booked in the next 90 days\n",
    "\n",
    "- `availability_365` - how many nights are available to be booked in the next 365 days\n",
    "\n",
    "- `number_of_reviews` - the number of reviews left for the property\n",
    "\n",
    "- `number_of_reviews_ltm` - the number of reviews left for the property in the last twelve months\n",
    "\n",
    "- `first_review` - the date of the first review\n",
    "\n",
    "- `last_review` - the date of the most recent review\n",
    "\n",
    "- `review_scores_rating` - guests can score properties overall from 1 to 5 stars\n",
    "\n",
    "- `review_scores_accuracy` - guests can score the accuracy of a property's description from 1 to 5 stars\n",
    "\n",
    "- `review_scores_cleanliness` - guests can score a property's cleanliness from 1 to 5 stars\n",
    "\n",
    "- `review_scores_checkin` - guests can score their check-in from 1 to 5 stars\n",
    "\n",
    "- `review_scores_communication` - guests can score a host's communication from 1 to 5 stars\n",
    "\n",
    "- `review_scores_location` - guests can score a property's location from 1 to 5 stars\n",
    "\n",
    "- `review_scores_value` - guests can score a booking's value for money from 1 to 5 stars\n",
    "\n",
    "- `instant_bookable` - whether or not the property can be instant booked (i.e. booked straight away, without having to message the host first and wait to be accepted)\n",
    "\n",
    "- `reviews_per_month` - calculated field of the average number of reviews left by guest each month\n",
    "\n",
    "\n",
    "The next two cells load the `listings.csv` file into a dataframe. Once loaded, start working on the subsequent questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 592,
     "status": "ok",
     "timestamp": 1621352489303,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "K4zobPQJzKAX"
   },
   "outputs": [],
   "source": [
    "### DO NOT CHANGE THIS CELL\n",
    "def load_csv(basedir):\n",
    "  return pd.read_csv(os.path.join(basedir, 'listings.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "executionInfo": {
     "elapsed": 2535,
     "status": "ok",
     "timestamp": 1621352491552,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "73pNEQSv5_WZ",
    "outputId": "991510f0-f1aa-47a6-df90-e96456dc1d23"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'listings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-547ede9339cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### DO NOT CHANGE THIS CELL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-dff778cec32a>\u001b[0m in \u001b[0;36mload_csv\u001b[0;34m(basedir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### DO NOT CHANGE THIS CELL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'listings.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'listings.csv'"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THIS CELL\n",
    "df = load_csv(basedir)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pzc714QhKf3g"
   },
   "source": [
    "## Question 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2061,
     "status": "ok",
     "timestamp": 1621352491553,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "8m6wSWKPJPLR"
   },
   "outputs": [],
   "source": [
    "# Do not rename the function, do not remove the return statement.\n",
    "# Just add code before the return statement to add the required functionality.\n",
    "def drop_cols(df):\n",
    "    \"\"\"\n",
    "    Drop all columns specified columns. Take dataframe as an input\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "        dataframe witout specified columns\n",
    "    \"\"\"\n",
    "    df = df.drop(['scrape_id','last_scraped','description','listing_url','neighbourhood','calendar_last_scraped', 'amenities','neighborhood_overview', 'picture_url','host_url', 'host_about', 'host_location','host_total_listings_count','host_thumbnail_url','host_picture_url', 'host_verifications','bathrooms_text','has_availability','minimum_minimum_nights','maximum_minimum_nights','minimum_maximum_nights','maximum_maximum_nights','minimum_nights_avg_ntm','maximum_nights_avg_ntm','number_of_reviews_l30d','calculated_host_listings_count','calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms','calculated_host_listings_count_shared_rooms'],1)\n",
    "    print(len(df.columns))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1784,
     "status": "ok",
     "timestamp": 1621352491554,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "GpBDncpjFrDh",
    "outputId": "9077bfa5-0da5-4505-e6f7-d24fafbe091d"
   },
   "outputs": [],
   "source": [
    "df = drop_cols(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1534,
     "status": "ok",
     "timestamp": 1621352491554,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "JgsX31bPJLfc"
   },
   "outputs": [],
   "source": [
    "def drop_cols_na(df, threshold):\n",
    "  \"\"\"\n",
    "    Drop all columns with more nan values than threshold\n",
    "    \n",
    "    Take dataframe as an input\n",
    "\n",
    "    Returns:\n",
    "        dataframe witout specified columns\n",
    "    \"\"\"\n",
    "  arr = []\n",
    "  for i in range (0,len(df.isnull().sum())):\n",
    "        #print(df.isnull().sum()[i])\n",
    "        #print(len(df))\n",
    "      complete = len(df) - df.isnull().sum()[i]\n",
    "      rate = complete / len(df) \n",
    "      if rate < threshold/100:\n",
    "          arr.append(i)\n",
    "  print(arr)    \n",
    "  df = df.drop(df.columns[arr], axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2854,
     "status": "ok",
     "timestamp": 1621352493126,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "y0DPwLXwSDGy",
    "outputId": "1713f3d0-87cf-4d18-c7c5-42c175630e44"
   },
   "outputs": [],
   "source": [
    "df = drop_cols_na(df, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2600,
     "status": "ok",
     "timestamp": 1621352493127,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "96fgXxHtgZuo",
    "outputId": "b66403b0-5543-4cab-e118-cefa9d4ea4b1"
   },
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6SMYnVDKt1d"
   },
   "source": [
    "## Question 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2156,
     "status": "ok",
     "timestamp": 1621352493127,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "lcw2iovWK-EN"
   },
   "outputs": [],
   "source": [
    "def binary_encoding(df):\n",
    "    \"\"\"\n",
    "    Change t values to 1\n",
    "    \n",
    "    Change f values to 0\n",
    "    \n",
    "    Take dataframe as an input\n",
    "\n",
    "    Returns:\n",
    "        dataframe with binary encoding\n",
    "    \"\"\"\n",
    "    for i in df.columns:\n",
    "        for j in range(0, len(df[i])):\n",
    "            if df[i][j] == \"t\":\n",
    "                df[i][j] = 1\n",
    "            elif df[i][j] == \"f\":\n",
    "                df[i][j] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25267,
     "status": "ok",
     "timestamp": 1621352516436,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "aZ7BoRBhlbYV"
   },
   "outputs": [],
   "source": [
    "df = binary_encoding(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24430,
     "status": "ok",
     "timestamp": 1621352516438,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "nKc_EqKdLDdV"
   },
   "outputs": [],
   "source": [
    "# hint: check Pandas to_datetime method\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "def add_host_days(df):\n",
    "    \"\"\"\n",
    "    Add host_days feature. There is host_since feature and use it to find total days after host registered.\n",
    "    \n",
    "    There is 55 nan values in host_days column and I prefered to drop them.\n",
    "\n",
    "    Returns:\n",
    "        dataframe with host_days feature\n",
    "    \"\"\"\n",
    "\n",
    "    arr = []\n",
    "    df = df[df['host_since'].notna()].reset_index() \n",
    "    df[\"host_days\"] = 0\n",
    "    today = date.today()\n",
    "    df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "    df = df[df['host_since'].notna()].reset_index() \n",
    "    \n",
    "    for i in range(0,len(df)):\n",
    "        arr.append((today - df.host_since[i].date()).days)\n",
    "    df.host_days = arr\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24222,
     "status": "ok",
     "timestamp": 1621352516438,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "1KNvK2SKLEcW"
   },
   "outputs": [],
   "source": [
    "def convert_price(df):\n",
    "    \"\"\"\n",
    "    Convert price, add unnecessary chars and make it clean\n",
    "\n",
    "    Returns:\n",
    "        dataframe\n",
    "    \"\"\"\n",
    "    for i in range (0,len(df[\"price\"])):\n",
    "        df[\"price\"][i] = float(df[\"price\"][i][1:].replace(\",\",\"\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23504,
     "status": "ok",
     "timestamp": 1621352517547,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "Jp08FU9IjQzG",
    "outputId": "6878d1d4-5037-4399-bb79-2eda3657f470"
   },
   "outputs": [],
   "source": [
    "df = add_host_days(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24786,
     "status": "ok",
     "timestamp": 1621352519617,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "MTGf_mt2iwwG"
   },
   "outputs": [],
   "source": [
    "df = convert_price(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1T-93iSQoXO"
   },
   "source": [
    "## Question 1c: Answering questions.\n",
    "\n",
    "You do not need to write the answer. In each cell, provide the Pandas code that outputs the result. Each answer can be given with 1-2 lines of Python code. Example question and answer:\n",
    "\n",
    "```python\n",
    "# What is the total number of rows in the dataframe?\n",
    "df.shape[0]\n",
    "```\n",
    "\n",
    "Now over to you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24073,
     "status": "ok",
     "timestamp": 1621352519618,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "gM3BRpVlni7z",
    "outputId": "86d0d578-fac9-4254-f9e1-be65ba08cd78"
   },
   "outputs": [],
   "source": [
    "# How many hosts offer 2 or more properties for rent?\n",
    "df_host = df.host_name.value_counts().to_dict()\n",
    "df_host = {name: offer for name, offer in df_host.items() if offer > 1}\n",
    "df_host_list_more_than_1 = list(df_host.keys())\n",
    "len(df_host_list_more_than_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23818,
     "status": "ok",
     "timestamp": 1621352519619,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "angGfYJxpOJ5",
    "outputId": "462a0f87-7c9f-49f4-a9fa-b24bb409aaf0"
   },
   "outputs": [],
   "source": [
    "# What is the highest price for a listing?\n",
    "max(df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 23555,
     "status": "ok",
     "timestamp": 1621352519620,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "TRMtPykhAji_",
    "outputId": "8962df4c-adcf-41ac-d8f7-e1f90f3347fb"
   },
   "outputs": [],
   "source": [
    "df[df.price == 8000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23310,
     "status": "ok",
     "timestamp": 1621352519620,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "WRiPS2fypnz3",
    "outputId": "5b6284e0-8f1b-40e3-dc06-752a106948cf"
   },
   "outputs": [],
   "source": [
    "# What is the ID of the listing that has the largest number of bedrooms?\n",
    "max(df.bedrooms)\n",
    "idxmax = df.bedrooms.idxmax()\n",
    "print(\"ID of the largest number of bedrooms: {}\".format(df.iloc[idxmax].id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23055,
     "status": "ok",
     "timestamp": 1621352519621,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "eu1cSceDnsM4",
    "outputId": "08c02dfa-a6d2-49d3-af8a-6c25f0d3d4c5"
   },
   "outputs": [],
   "source": [
    "# What is the ID of the listing with the largest advertised price\n",
    "df.price = pd.to_numeric(df['price'])\n",
    "idmax = df.price.idxmax()\n",
    "print(\"ID of the largest advertised price: {}\".format(df.iloc[idmax].id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5611,
     "status": "ok",
     "timestamp": 1621352519621,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "ZhzBksbCumZB",
    "outputId": "9d5772ea-fd8a-439c-c1ba-77ad5ca48942"
   },
   "outputs": [],
   "source": [
    "# There are different room types. How many listings are there for the most common room type?\n",
    "max_listing_room_type = max(df.room_type.value_counts().to_dict().values())\n",
    "print(\"Most common room-type listing number: {}\".format(max_listing_room_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5054,
     "status": "ok",
     "timestamp": 1621352519622,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "clsRn8tEVw4a",
    "outputId": "774fb5f7-04a8-447d-a43a-26461666583d"
   },
   "outputs": [],
   "source": [
    "# How many hosts are there that have been registered for more than 3000 days?\n",
    "print(\"Hosts have been registered for more than 3000 days: {}\".format(len(df[df.host_days > 3000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_a4I7y_FsVI0"
   },
   "source": [
    "## Question 1d: Exploratory analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcA5tI8ftsFS"
   },
   "source": [
    "Produce a barplot of the average nightly price per neighbourhood as instructed in the Coursework proforma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "executionInfo": {
     "elapsed": 5165,
     "status": "ok",
     "timestamp": 1621352520773,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "psZPbywKFV27",
    "outputId": "e920cc48-5a4a-4cb2-b538-3215f4e19143"
   },
   "outputs": [],
   "source": [
    "neighbourhood_list = df.neighbourhood_cleansed.unique()\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x = \"price\", y = \"neighbourhood_cleansed\", data= df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "834GVr84yfAA"
   },
   "source": [
    "Plot a correlation matrix as instructed in the Coursework proforma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 2119,
     "status": "ok",
     "timestamp": 1621352522947,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "fvS5_JdIFQbG",
    "outputId": "79ab69ea-1d42-47d2-dfce-4bf5777441a5"
   },
   "outputs": [],
   "source": [
    "df_rev = df.iloc[:,36:41]\n",
    "corr = df_rev.corr()\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbQSmGzNe6be"
   },
   "source": [
    "Plot a geographical distribution as instructed in the Coursework proforma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4148,
     "status": "ok",
     "timestamp": 1621352528372,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "jsQg0QIjo2cc",
    "outputId": "2d102fbf-198c-4768-9ed7-a77a9a8463fd"
   },
   "outputs": [],
   "source": [
    "!pip install chart_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 3899,
     "status": "ok",
     "timestamp": 1621352528373,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "qbTja8fwFScc",
    "outputId": "917caa8f-2193-43be-c447-4490e70cb8ae"
   },
   "outputs": [],
   "source": [
    "df_price_150 = df[df.price > 150].reset_index(drop=True)\n",
    "df_price_150.price = pd.to_numeric(df_price_150['price'])\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import cufflinks\n",
    "\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3975,
     "status": "ok",
     "timestamp": 1621352528996,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "khU7w2-DroMA"
   },
   "outputs": [],
   "source": [
    "df_price_150[\"color\"] = 0\n",
    "\n",
    "price_arr = list(df_price_150.price)\n",
    "color_arr = []\n",
    "\n",
    "for i in range(0,len(price_arr)):\n",
    "    \n",
    "    if price_arr[i] >= 150 and price_arr[i] < 300:\n",
    "        color_arr.append(150)\n",
    "    elif price_arr[i] >= 300 and price_arr[i] < 450:\n",
    "        color_arr.append(300)\n",
    "    elif price_arr[i] >= 450 and price_arr[i] < 600:\n",
    "        color_arr.append(450)\n",
    "    elif price_arr[i] >= 600 and price_arr[i] < 750:\n",
    "        color_arr.append(600)\n",
    "    elif price_arr[i] >= 750:\n",
    "        color_arr.append(750)\n",
    "        \n",
    "df_price_150.color = color_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 5328,
     "status": "ok",
     "timestamp": 1621352530616,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "2gSlDcJorpEf",
    "outputId": "212694f4-61c5-459e-841d-03c19a804d5d"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(df_price_150, y = \"latitude\", x = \"longitude\", size = \"price\", color = \"price\", hover_data=[\"price\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize = (20,10))\n",
    "\n",
    "df_150 = df[df[\"price\"] > 150]\n",
    "\n",
    "sns.scatterplot(x=\"longitude\", y=\"latitude\", data=df_150,  hue=\"price\",palette = \"flare\", size=\"price\", sizes = (50,500))\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dLbkYk6y9eF"
   },
   "source": [
    "---\n",
    "\n",
    "# Part 2: Statistical analysis and recommender system\n",
    "## CMT 309 Data Science Portfolio\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Answer the questions by filling in the appropriate sections. \n",
    "- Do not remove or rename section headings or any code that has been provided, unless instructed otherwise.\n",
    "- You can add as many additional cells with code as you like.\n",
    "- Sometimes you are asked to provide an answer or justification. To this end, double-click on the text cells and add your answer/explanation following the text \"YOUR ANSWER:\".\n",
    "\n",
    "Before submitting,\n",
    "\n",
    "- Ensure that the code is clean, readable, and well documented. \n",
    "- Restart the kernel (to wipe all variables) and then run the code from top to bottom to produce all intermediate outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtpZraSiE00A"
   },
   "source": [
    "## Question 2a: Linear regression and t-tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 4401,
     "status": "ok",
     "timestamp": 1621352530617,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "RDCTzGiooPDJ",
    "outputId": "f2292de2-6a3c-4fd0-f74b-1b45917177c5"
   },
   "outputs": [],
   "source": [
    "df_review = df.iloc[:,34:41]   # select the relayed columns\n",
    "df_review = df_review.dropna()  # almost 15% is nan value so drop them all\n",
    "# change columns name\n",
    "df_review.columns = [\"overall_rating\",\"accuracy\", \"cleanliness\", \"checkin\", \"communication\", \"location\", \"value\"]\n",
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1339,
     "status": "ok",
     "timestamp": 1621352532036,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "rqyTKjcDTSzH"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1342,
     "status": "ok",
     "timestamp": 1621352532036,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "KvMMP72uTaFq"
   },
   "outputs": [],
   "source": [
    "# linear regression with Ordinary least squares / stat\n",
    "fit = sm.OLS.from_formula('overall_rating ~ accuracy + cleanliness + checkin + communication + location + value', df_review).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1323,
     "status": "ok",
     "timestamp": 1621352532037,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "HUfJ9WEITaP5",
    "outputId": "d884131c-11f7-483c-bfb1-490079930527"
   },
   "outputs": [],
   "source": [
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9Lalo7srWMr"
   },
   "source": [
    "**T-test questions**:\n",
    "\n",
    "Which room types are significantly different in terms of nightly price?\n",
    "\n",
    "YOUR ANSWER (1-2 sentences): ...[double click to edit]...\n",
    "\n",
    "Do the significances change if you perform Bonferroni correction to the alpha level: https://en.wikipedia.org/wiki/Bonferroni_correction ?\n",
    "\n",
    "YOUR ANSWER (1-2 sentences): ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1621352541422,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "sxPSFtH0U8Tb"
   },
   "outputs": [],
   "source": [
    "# extract prices for all room types\n",
    "\n",
    "price_private = df[df.room_type == 'Private room'].price\n",
    "price_home = df[df.room_type == 'Entire home/apt'].price\n",
    "price_hotel = df[df.room_type == 'Hotel room'].price\n",
    "price_shared = df[df.room_type == 'Shared room'].price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1103,
     "status": "ok",
     "timestamp": 1621352541659,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "zcKLLf6tXyyx"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(price_private.mean())\n",
    "print(price_home.mean())\n",
    "print(price_hotel.mean())\n",
    "print(price_shared.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [price_private, price_home, price_hotel, price_shared]  # put all room_type prices in arr for iteration\n",
    "names = [\"price_private\", \"price_home\", \"price_hotel\", \"price_shared\"] # all names of room_types\n",
    "\n",
    "p_value_df = pd.DataFrame(index= names, columns= names)  # define null df\n",
    "\n",
    "for i,j in zip(arr,names):    # fill dataframe with p values\n",
    "    for a,b in zip(arr,names):\n",
    "        t_stat, p = ttest_ind(i, a)  # calculate p values and put it in dataframe \n",
    "        p_value_df.at[j, b] = p\n",
    "        \n",
    "p_value_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are 6 unique hypotesis in total. \n",
    "\n",
    "#This is why as a definifion of Bonferroni, we should divide p value / 6.\n",
    "\n",
    "unique_hypothesis_number = 6\n",
    "\n",
    "alpha = 0.01 \n",
    "\n",
    "Bonferroni_alpha = alpha / unique_hypothesis_number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* According to alpha = 0.01 threshold, As we can see in the table;\n",
    "\n",
    "1- Private room ~ Entire home/apt\n",
    "\n",
    "2- Private room ~ Hotel room\n",
    "\n",
    "3- Hotel room ~ Entire home/apt\n",
    "\n",
    "4- Shared room ~ Entire home/apt\n",
    "\n",
    "The price of these room_type pair are significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bonferroni_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we change alpha with Bonferroni_alpha this time;\n",
    "\n",
    "1- Hotel room ~ Private room\n",
    "\n",
    "2- Entire home/apt ~ Private room\n",
    "\n",
    "these price pairs are significantly different according to Bonferroni_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8mwnrOhboSC"
   },
   "source": [
    "## Question 2b: Linear regression with variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5aMn9YWrNnI"
   },
   "source": [
    "Provide a short justification (2-3 sentences) for your choice of variables.\n",
    "\n",
    "YOUR ANSWER: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1621352560708,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "28eT8fV8c_27"
   },
   "outputs": [],
   "source": [
    "def variable_selection(df, predictors, target, alpha):\n",
    "    \"\"\"\n",
    "    Find significant variables. To to that we will use r2 and p values. \n",
    "    \n",
    "    Room type is a categorical so apply get_dummies. It is like a onehot encoder.\n",
    "    \n",
    "    First: Rsquare value should be calculate one by one and take the feature with highest r2 value,\n",
    "    \n",
    "    add it in an arry to collect and do same process now make ols with first collected value and other \n",
    "    \n",
    "    variable comes from predictors. Iterate this process until the columns left dont give \n",
    "    \n",
    "    contibution to increase r2 value\n",
    "    \n",
    "    Second: Now take the all significant predictors comes from r2 selector and extract values which have bigger p value.\n",
    "    \n",
    "    If all p values are lower than alpha than features left are most significant variables\n",
    "    \n",
    "    Take dataframe as an input\n",
    "\n",
    "    Returns:\n",
    "        the array of significant features\n",
    "    \"\"\"\n",
    "    df.fillna(value = df[predictors].mean(), inplace = True)\n",
    "    \n",
    "    \n",
    "    df_ols = pd.get_dummies(df[predictors], columns=['room_type'])\n",
    "    predictors = df_ols.columns.values.tolist()\n",
    "    df_ols_target = df[target]\n",
    "    print(predictors)\n",
    "    arr = [] # we will store elements with highest r2 in this arr\n",
    "    counter = 0 # define counter to escape while loop\n",
    "\n",
    "    while counter < len(df_ols.columns): # iterate over length of features\n",
    "      counter = counter + 1. \n",
    "      r2_value = 0   # we will store highest r2 value in here so start with 0\n",
    "      best_predictor = \"\"  # we will store name of feature with highest r2 value in here\n",
    "      for i in predictors:\n",
    "        arrx = []       # every time we create a array with feature comes from for loop\n",
    "        arrx.append(i)\n",
    "        arrx = arrx + arr  # merge it with array\n",
    "        ols = sm.OLS(df_ols_target.price, df_ols[arrx]).fit()   # calculate ols\n",
    "        r2 = ols.rsquared # calculate r2\n",
    "\n",
    "        if r2 > r2_value: #if current r2 is bigger than previous our new biggest r2_value is our current r2 so change it and also take the feature name\n",
    "          r2_value = r2\n",
    "          best_predictor = i\n",
    "        else:   # if previous is bigger than current, do nothing it means current feature didnt contribute more to increase r2 value like previous feature\n",
    "          r2_value = r2_value\n",
    "          best_predictor = best_predictor\n",
    "      predictors.remove(best_predictor) # after all iteration we found best feature which is more effective to increase r2 value remove it to predictors because we already analized it.\n",
    "\n",
    "      if counter > 1:    # in the cell below I calculate ols.r2 but if counter < 1, arr is null so  df_ols[arr] will give error to protect it i write a conditional if loop.\n",
    "        calc_r2_1 = sm.OLS(df_ols_target.price, df_ols[arr]).fit().rsquared # previous r2\n",
    "        arr.append(best_predictor)\n",
    "        calc_r2_2 = sm.OLS(df_ols_target.price, df_ols[arr]).fit().rsquared # current r2\n",
    "        \n",
    "        if calc_r2_1 > calc_r2_2:   # if current r2 lower than previous than feature decrease the r2 score so break the function\n",
    "          arr = arr[:-1]\n",
    "          break\n",
    "        else:\n",
    "          arr = arr\n",
    "      else:   # if counter < 0 , then our r2 value is 0 so, there is no need to compare.\n",
    "        arr.append(best_predictor)\n",
    "        #print(sm.OLS(df_ols_target.price, df_ols[arr]).fit().rsquared)\n",
    "\n",
    "    #print(arr) # print all effective features\n",
    "    \n",
    "    \n",
    "    ### SELECTION BASED ON P VALUE ####################\n",
    "    \n",
    "    counter = 0\n",
    "    alpha = 0.01\n",
    "\n",
    "    while counter < len(arr):  # iterate 0 to length of features\n",
    "      #print(predictors)\n",
    "      counter = counter +1 # define counter to escape loop\n",
    "      a = sm.OLS(df_ols_target.price, df_ols[arr]).fit() # calculate ols\n",
    "      dic = a.pvalues.to_dict() # take all p values of features and convert this to dictionary\n",
    "      if max(dic.values()) > alpha:      # if there is a value over than value of alpha then start reducing operation\n",
    "        dic = a.pvalues.to_dict()   # again take the values\n",
    "        for key, value in dic.items():  # take key and value pairs to find max value\n",
    "          if value > alpha: \n",
    "            v=list(dic.values()) # all values\n",
    "            k=list(dic.keys()) # all keys\n",
    "            largest_p_feature = k[v.index(max(v))] # find index of max value and then put it on key lists to find feature with largest key\n",
    "            #print(largest_p_feature)\n",
    "            arr.remove(largest_p_feature) # remove this key(feature)\n",
    "            break\n",
    "    #print(arr)\n",
    "    \n",
    "    return arr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c8e3822438e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To keep it simple, I will select numerical features + room_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_cropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"float64\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"level_0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cropped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# To keep it simple, I will select numerical features + room_type\n",
    "df_cropped = df[df.select_dtypes(include=[\"float64\",\"int64\"]).drop([\"level_0\", \"index\"],1).columns.to_list()]\n",
    "\n",
    "corr = df_cropped.head(10000).corr()\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-As we can see in the heatmap, price is  realted with beds, bedrooms and accomodate. Except those features, I add \n",
    "room_type as categorial and add another features because I think they might be related.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1064,
     "status": "ok",
     "timestamp": 1621352558711,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "scF86NcJc_vA"
   },
   "outputs": [],
   "source": [
    "predictors = [\"accommodates\", \"bedrooms\", \"beds\",  \"minimum_nights\",  \"maximum_nights\",  \"number_of_reviews\", \"review_scores_rating\", \"host_days\" , \"reviews_per_month\", \"room_type\"]\n",
    "target = [\"price\"]\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_variables = variable_selection(df, predictors, target, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzz5uexvkgil"
   },
   "source": [
    "## Question 2c: Recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uW-LealN0kOU"
   },
   "source": [
    "### Recommend a neighbourhood given a budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1621349579552,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "XefWzPW6efYU"
   },
   "outputs": [],
   "source": [
    "def recommend_neighbourhood(df, budget_min, budget_max, relative):\n",
    "    \"\"\"\n",
    "    build a recommendation system. take min and max budgets and also take relative value which means if it is true\n",
    "    \n",
    "    take a fraction and then find neighbourhood with most fraction. If it is false, find the neighbourhood with\n",
    "    \n",
    "    most properties in specified price index.\n",
    "\n",
    "    Returns:\n",
    "        recommended neighbourhood name\n",
    "    \"\"\"\n",
    "    if relative == False: # if relative false take real values\n",
    "        dic = df[(df.price <= budget_max) & (df.price >= budget_min)][[\"neighbourhood_cleansed\"]].value_counts().to_dict() # filter df and take neighbourhood_cleansed find frequency and make it dict\n",
    "        v=list(dic.values()) # all values\n",
    "        k=list(dic.keys()) # all keys\n",
    "\n",
    "        neighbourhood = k[v.index(max(v))]\n",
    "        return neighbourhood[0]\n",
    "    else:  # if relative  =  true take fraction\n",
    "        dic1 = df[[\"neighbourhood_cleansed\"]].value_counts().to_dict()\n",
    "        dic2 = df[(df.price <= budget_max) & (df.price >= budget_min)][[\"neighbourhood_cleansed\"]].value_counts().to_dict() # filter df and take neighbourhood_cleansed find frequency and make it dict\n",
    "\n",
    "        for key, value in dic2.items():  # find fractions\n",
    "          fraction = value / dic1[key]  # values with filter / values without filter\n",
    "          dic2[key] = fraction # change values\n",
    "\n",
    "        v=list(dic2.values()) # all values\n",
    "        k=list(dic2.keys()) # all keys\n",
    "        neighbourhood = k[v.index(max(v))]\n",
    "        return neighbourhood[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1621353438887,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "AVWPIAI2egfT",
    "outputId": "b47b990c-312e-4a40-a279-519c34bf89ba"
   },
   "outputs": [],
   "source": [
    "recommend_neighbourhood(df, 100.0, 300.0, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-FSWRJ6zSMM"
   },
   "source": [
    "### Price recommender for hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1621357705291,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "kfuTEZDre6bn"
   },
   "outputs": [],
   "source": [
    "def recommend_price(df, latitude, longitude, n_neighbours, room_type = None):\n",
    "    \"\"\"\n",
    "    make a recommendation system to determine the price of property. Take the location values and \n",
    "    \n",
    "    n_neighbours value which is important because based on it, we will find an average value.\n",
    "    \n",
    "    find Euclidean distance in terms of latitude/longitude of all properties between given latitude/longitude values as\n",
    "    \n",
    "    parameters. Sort them, take neares \"n_neighbours\" values and find mean\n",
    "\n",
    "    Returns:\n",
    "        recommended average price\n",
    "    \"\"\"\n",
    "\n",
    "    df_reco = df[[\"room_type\", \"price\", \"latitude\" ,\"longitude\"]] # create df_reco dataset\n",
    "\n",
    "    df_reco[\"distance\"] = ((df_reco.latitude-latitude)**2 + (df_reco.longitude-longitude)**2)**(1/2) # create new column and calculate distance\n",
    "\n",
    "    if room_type in df_reco.room_type.unique():   # if room_type variable is in room_type.uniique\n",
    "        df_reco = df_reco[df_reco.room_type == room_type] # filter df_reco\n",
    "\n",
    "    avg_price = df_reco.sort_values('distance', ascending = True).head(n_neighbours).price.mean() #sort values based of distance take take top n_neighbours of raw and take mean\n",
    "  \n",
    "  \n",
    "    return avg_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 971,
     "status": "ok",
     "timestamp": 1621357340809,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "qRlLYIcrwl5c",
    "outputId": "7ed21166-ce28-4ab4-924e-31e16f80ff85"
   },
   "outputs": [],
   "source": [
    "recommend_price(df, 52.37297, 4.88339, 10, 'Entire home/apt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1621357705501,
     "user": {
      "displayName": "Can Uzuner",
      "photoUrl": "",
      "userId": "11260252464507881293"
     },
     "user_tz": -60
    },
    "id": "4oEqlCiWu2rS",
    "outputId": "7043acbe-6c88-4749-f178-98c6a6ad1d23"
   },
   "outputs": [],
   "source": [
    "recommend_price(df, 52.36609, 4.91143, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part1_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
